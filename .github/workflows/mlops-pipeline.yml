# ============================================================================
# GitHub Actions CI/CD Pipeline for MLOps Consumer Complaints Classifier
# ============================================================================

name: MLOps CI/CD Pipeline

on:
  push:
    branches:
      - main
      - develop
    paths:
      - 'src/**'
      - 'tests/**'
      - 'requirements.txt'
      - '.github/workflows/**'
  
  pull_request:
    branches:
      - main
      - develop
  
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - production
      sample_size:
        description: 'Training sample size'
        required: false
        default: '5000'
      deploy_endpoint:
        description: 'Deploy to endpoint'
        required: false
        default: 'true'
        type: boolean

permissions:
  id-token: write
  contents: read
  
env:
  PYTHON_VERSION: '3.11'
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  REGION: 'us-central1'
  MODEL_DISPLAY_NAME: 'consumer-complaints-classifier'
  ENDPOINT_DISPLAY_NAME: 'consumer-complaints-endpoint'

jobs:
  # ==========================================================================
  # JOB 1: CODE QUALITY CHECKS
  # ==========================================================================
  code-quality:
    name: Code Quality & Linting
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install linting tools
        run: |
          pip install black flake8 isort
      
      - name: Run Black (formatting check)
        run: |
          black --check --diff src/ tests/ || true
      
      - name: Run isort (import sorting)
        run: |
          isort --check-only --diff src/ tests/ || true
      
      - name: Run Flake8 (linting)
        run: |
          flake8 src/ tests/ --max-line-length=100 --exclude=__init__.py || true
      
      - name: Code quality summary
        if: always()
        run: |
          echo "## Code Quality Report" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Code quality checks completed" >> $GITHUB_STEP_SUMMARY

  # ==========================================================================
  # JOB 2: UNIT TESTS
  # ==========================================================================
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: code-quality
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install tensorflow tensorflow-hub google-cloud-aiplatform
          pip install pytest pytest-cov
          pip install -r requirements.txt || true
      
      - name: Run unit tests
        run: |
          pytest tests/unit/ -v --tb=short || echo "No unit tests found yet"
      
      - name: Test summary
        if: always()
        run: |
          echo "## Unit Test Results" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Unit tests completed" >> $GITHUB_STEP_SUMMARY

  # ==========================================================================
  # JOB 3: MODEL TRAINING (DEV/STAGING)
  # ==========================================================================
  model-training:
    name: Train Model
    runs-on: ubuntu-latest
    needs: unit-tests
    if: github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/main'
    
    outputs:
      model_version: ${{ steps.set-version.outputs.version }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install tensorflow tensorflow-hub
          pip install google-cloud-bigquery google-cloud-storage google-cloud-aiplatform
          pip install pandas numpy scikit-learn datasets
          pip install -r requirements.txt || true
      
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
      
      - name: Set model version
        id: set-version
        run: |
          VERSION=$(date +%Y%m%d_%H%M%S)_${GITHUB_SHA:0:7}
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "MODEL_VERSION=$VERSION" >> $GITHUB_ENV
      
      - name: Train model on sample data
        run: |
          python src/training/train.py \
            --project-id ${{ secrets.GCP_PROJECT_ID }} \
            --sample-size ${{ github.event.inputs.sample_size || '1000' }} \
            --epochs 2 \
            --model-type use \
            --output-path ./models/trained
      
      - name: Upload model artifacts
        uses: actions/upload-artifact@v4
        with:
          name: trained-model
          path: |
            models/trained/*.keras
            models/trained/*.pkl
            models/trained/metadata.json
          retention-days: 30
      
      - name: Training summary
        if: always()
        run: |
          echo "## Model Training Results" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Model training completed" >> $GITHUB_STEP_SUMMARY
          echo "**Model Version:** ${{ env.MODEL_VERSION }}" >> $GITHUB_STEP_SUMMARY
          if [ -f models/trained/metadata.json ]; then
            echo "### Metadata:" >> $GITHUB_STEP_SUMMARY
            cat models/trained/metadata.json >> $GITHUB_STEP_SUMMARY
          fi

  # ==========================================================================
  # JOB 4: UPLOAD MODEL TO GCS
  # ==========================================================================
  upload-model:
    name: Upload Model to GCS
    runs-on: ubuntu-latest
    needs: model-training
    if: github.ref == 'refs/heads/main'
    
    outputs:
      gcs_model_path: ${{ steps.upload.outputs.gcs_path }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download model artifacts
        uses: actions/download-artifact@v4
        with:
          name: trained-model
          path: ./models/trained
      
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}
      
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
      
      - name: Upload to GCS
        id: upload
        run: |
          MODEL_VERSION=${{ needs.model-training.outputs.model_version }}
          GCS_PATH="gs://${{ secrets.GCS_BUCKET }}/models/production/${MODEL_VERSION}"
          
          gsutil -m cp -r models/trained/* ${GCS_PATH}/
          echo "gcs_path=${GCS_PATH}" >> $GITHUB_OUTPUT
          echo "âœ… Model uploaded to: ${GCS_PATH}"
      
      - name: Upload summary
        run: |
          echo "## Model Upload" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Model uploaded to GCS" >> $GITHUB_STEP_SUMMARY
          echo "**GCS Path:** ${{ steps.upload.outputs.gcs_path }}" >> $GITHUB_STEP_SUMMARY

  # ==========================================================================
  # JOB 5: REGISTER MODEL IN VERTEX AI
  # ==========================================================================
  register-model:
    name: Register Model in Vertex AI
    runs-on: ubuntu-latest
    needs: [model-training, upload-model]
    if: github.ref == 'refs/heads/main'
    
    outputs:
      model_resource_name: ${{ steps.register.outputs.model_name }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
           pip install tensorflow tensorflow_hub google-cloud-aiplatform google-cloud-storage
      
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}
      
      - name: Register model in Vertex AI
        id: register
        run: |
          python - <<EOF
          from google.cloud import aiplatform
          import tensorflow as tf
          from google.cloud import storage
          import sys
          import os

          # CRITICAL: Import custom layers before loading the model
          # Add your project's source code to the path
          sys.path.insert(0, os.path.join(os.getcwd(), 'src.models')) 

          # Import your custom layer
          from src.models.use_classifier import USEEmbeddingLayer  # Adjust import path as needed

          
          model_version = "${{ needs.model-training.outputs.model_version }}"

          # Download model from GCS
          storage_client = storage.Client()
          bucket = storage_client.bucket("${{ secrets.GCS_BUCKET }}")
          blob = bucket.blob(f"models/production/{model_version}/model.keras")
          blob.download_to_filename("model.keras")

          # Load with custom function
          # after defining custom_standardization (in train.py)
          try:
              import tensorflow as tf
              register = tf.keras.utils.register_keras_serializable
          except Exception:
              # fallback to standalone keras saving API
              try:
                  from keras.saving import register_keras_serializable as register
              except Exception:
                  # no-op
                  def register(*a, **kw):
                      def _d(fn): return fn
                      return _d

          register(package='Custom')(custom_standardization)
          def custom_standardization(input_data):
              lowercase = tf.strings.lower(input_data)
              no_html = tf.strings.regex_replace(lowercase, '<[^>]+>', ' ')
              no_urls = tf.strings.regex_replace(no_html, r'http\S+|www\S+', ' ')
              no_emails = tf.strings.regex_replace(no_urls, r'\S+@\S+', ' ')
              no_redacted = tf.strings.regex_replace(no_emails, r'x{2,}', ' ')
              no_numbers = tf.strings.regex_replace(no_redacted, r'\d+', ' ')
              no_punct = tf.strings.regex_replace(no_numbers, r'[^a-z\s\-]', ' ')
              cleaned = tf.strings.regex_replace(no_punct, r'\s+', ' ')
              return tf.strings.strip(cleaned)

          # Load the .keras model
          model = tf.keras.models.load_model('complete_complaint_classifier_tf.keras', custom_objects={"custom_standardization": custom_standardization})
          model.export("saved_model/")


          # Upload SavedModel back to GCS
          import os
          for root, dirs, files in os.walk("saved_model/"):
              for file in files:
                  local_path = os.path.join(root, file)
                  gcs_path = local_path.replace("saved_model/", f"models/production/{model_version}/")
                  blob = bucket.blob(gcs_path)
                  blob.upload_from_filename(local_path)

          print("Model converted and uploaded successfully!")


          # Upload model to Vertex AI Model Registry
          vertex_model = aiplatform.Model.upload(
              display_name="${{ env.MODEL_DISPLAY_NAME }}",
              artifact_uri=f"gs://${{ secrets.GCS_BUCKET }}/models/production/${{ needs.model-training.outputs.model_version }}/",
              serving_container_image_uri="us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest",
              description=f"Consumer complaints classifier - Version ${{ needs.model-training.outputs.model_version }}",
              labels={
                  "version": model_version.replace("_", "-").replace(".", "-")[:63],
                  "environment": "production",
                  "framework": "tensorflow",
                  "model-type": "use-classifier"
              }
          )
          
          print(f"Model registered: {vertex_model.resource_name}")  # Changed from model to vertex_model
          # Save model resource name
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"model_name={vertex_model.resource_name}\n")
          EOF
      
      - name: Registration summary
        run: |
          echo "## Vertex AI Model Registration" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Model registered in Vertex AI Model Registry" >> $GITHUB_STEP_SUMMARY
          echo "**Model Resource Name:** ${{ steps.register.outputs.model_name }}" >> $GITHUB_STEP_SUMMARY

  # ==========================================================================
  # JOB 6: DEPLOY MODEL TO VERTEX AI ENDPOINT
  # ==========================================================================
  deploy-endpoint:
    name: Deploy Model to Vertex AI Endpoint
    runs-on: ubuntu-latest
    needs: [model-training, register-model]
    if: github.ref == 'refs/heads/main' && (github.event.inputs.deploy_endpoint != 'false')
    
    outputs:
      endpoint_id: ${{ steps.deploy.outputs.endpoint_id }}
      endpoint_url: ${{ steps.deploy.outputs.endpoint_url }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install google-cloud-aiplatform
      
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}
      
      - name: Deploy model to endpoint
        id: deploy
        run: |
          python - <<EOF
          from google.cloud import aiplatform
          import os
          
          aiplatform.init(
              project="${{ env.PROJECT_ID }}",
              location="${{ env.REGION }}"
          )
          
          # Get the registered model
          model = aiplatform.Model("${{ needs.register-model.outputs.model_resource_name }}")
          
          # Check if endpoint exists
          endpoints = aiplatform.Endpoint.list(
              filter=f'display_name="${{ env.ENDPOINT_DISPLAY_NAME }}"'
          )
          
          if endpoints:
              endpoint = endpoints[0]
              print(f"Using existing endpoint: {endpoint.resource_name}")
              
              # Undeploy previous models (optional - or use traffic splitting)
              for deployed_model in endpoint.list_models():
                  try:
                      endpoint.undeploy(deployed_model_id=deployed_model.id)
                      print(f"Undeployed model: {deployed_model.id}")
                  except Exception as e:
                      print(f"Could not undeploy model {deployed_model.id}: {e}")
          else:
              # Create new endpoint
              endpoint = aiplatform.Endpoint.create(
                  display_name="${{ env.ENDPOINT_DISPLAY_NAME }}",
                  description="Consumer complaints classifier endpoint"
              )
              print(f"Created new endpoint: {endpoint.resource_name}")
          
          # Deploy model to endpoint
          model.deploy(
              endpoint=endpoint,
              deployed_model_display_name="${{ env.MODEL_DISPLAY_NAME }}-${{ needs.model-training.outputs.model_version }}",
              machine_type="n1-standard-4",
              min_replica_count=1,
              max_replica_count=3,
              traffic_percentage=100,
              accelerator_type=None,
              accelerator_count=0
          )
          
          print(f"Model deployed to endpoint: {endpoint.resource_name}")
          
          # Save outputs
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"endpoint_id={endpoint.name}\n")
              f.write(f"endpoint_url=https://{os.environ['REGION']}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:predict\n")
          EOF
      
      - name: Test endpoint
        run: |
          python - <<EOF
          from google.cloud import aiplatform
          
          aiplatform.init(
              project="${{ env.PROJECT_ID }}",
              location="${{ env.REGION }}"
          )
          
          endpoint = aiplatform.Endpoint("${{ steps.deploy.outputs.endpoint_id }}")
          
          # Test prediction
          test_instances = [
              {"text": "I have a problem with my credit card billing"}
          ]
          
          try:
              predictions = endpoint.predict(instances=test_instances)
              print("âœ… Endpoint test successful")
              print(f"Sample prediction: {predictions.predictions[0] if predictions.predictions else 'No predictions'}")
          except Exception as e:
              print(f"âš ï¸ Endpoint test failed: {e}")
          EOF
      
      - name: Deployment summary
        run: |
          echo "## Vertex AI Endpoint Deployment" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Model deployed to Vertex AI endpoint" >> $GITHUB_STEP_SUMMARY
          echo "**Endpoint ID:** ${{ steps.deploy.outputs.endpoint_id }}" >> $GITHUB_STEP_SUMMARY
          echo "**Endpoint URL:** ${{ steps.deploy.outputs.endpoint_url }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Test the endpoint:" >> $GITHUB_STEP_SUMMARY
          echo '```bash' >> $GITHUB_STEP_SUMMARY
          echo 'gcloud ai endpoints predict ${{ steps.deploy.outputs.endpoint_id }} \' >> $GITHUB_STEP_SUMMARY
          echo '  --region=${{ env.REGION }} \' >> $GITHUB_STEP_SUMMARY
          echo '  --json-request=request.json' >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

  # ==========================================================================
  # JOB 7: DEPLOYMENT NOTIFICATION
  # ==========================================================================
  notify:
    name: Send Notification
    runs-on: ubuntu-latest
    needs: [code-quality, unit-tests, model-training, upload-model, register-model, deploy-endpoint]
    if: always()
    
    steps:
      - name: Check job statuses
        run: |
          echo "Pipeline Status:"
          echo "  Code Quality: ${{ needs.code-quality.result }}"
          echo "  Unit Tests: ${{ needs.unit-tests.result }}"
          echo "  Model Training: ${{ needs.model-training.result }}"
          echo "  Upload Model: ${{ needs.upload-model.result }}"
          echo "  Register Model: ${{ needs.register-model.result }}"
          echo "  Deploy Endpoint: ${{ needs.deploy-endpoint.result }}"
      
      - name: Create summary
        run: |
          echo "# ðŸš€ MLOps Pipeline Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Pipeline Results:" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Code Quality: ${{ needs.code-quality.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Unit Tests: ${{ needs.unit-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Model Training: ${{ needs.model-training.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Upload Model: ${{ needs.upload-model.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Register Model: ${{ needs.register-model.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Deploy Endpoint: ${{ needs.deploy-endpoint.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Deployment Details:" >> $GITHUB_STEP_SUMMARY
          echo "**Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "**Author:** ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
          echo "**Model Version:** ${{ needs.model-training.outputs.model_version }}" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.deploy-endpoint.result }}" == "success" ]; then
            echo "**Endpoint ID:** ${{ needs.deploy-endpoint.outputs.endpoint_id }}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ðŸŽ¯ Quick Start:" >> $GITHUB_STEP_SUMMARY
            echo '```python' >> $GITHUB_STEP_SUMMARY
            echo 'from google.cloud import aiplatform' >> $GITHUB_STEP_SUMMARY
            echo 'endpoint = aiplatform.Endpoint("${{ needs.deploy-endpoint.outputs.endpoint_id }}")' >> $GITHUB_STEP_SUMMARY
            echo 'predictions = endpoint.predict(instances=[{"text": "Your complaint here"}])' >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi