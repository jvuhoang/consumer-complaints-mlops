# ============================================================================
# GitHub Actions CI/CD Pipeline for MLOps Consumer Complaints Classifier
# ============================================================================

name: MLOps CI/CD Pipeline

on:
  push:
    branches:
      - main
      - develop
    paths:
      - 'src/**'
      - 'tests/**'
      - 'requirements.txt'
      - '.github/workflows/**'
  
  pull_request:
    branches:
      - main
      - develop
  
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - production
      sample_size:
        description: 'Training sample size'
        required: false
        default: '5000'

permissions:
  id-token: write
  contents: read
  
env:
  PYTHON_VERSION: '3.11'
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  REGION: 'us-central1'

jobs:
  # ==========================================================================
  # JOB 1: CODE QUALITY CHECKS
  # ==========================================================================
  code-quality:
    name: Code Quality & Linting
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install linting tools
        run: |
          pip install black flake8 isort
      
      - name: Run Black (formatting check)
        run: |
          black --check --diff src/ tests/ || true
      
      - name: Run isort (import sorting)
        run: |
          isort --check-only --diff src/ tests/ || true
      
      - name: Run Flake8 (linting)
        run: |
          flake8 src/ tests/ --max-line-length=100 --exclude=__init__.py || true
      
      - name: Code quality summary
        if: always()
        run: |
          echo "## Code Quality Report" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Code quality checks completed" >> $GITHUB_STEP_SUMMARY

  # ==========================================================================
  # JOB 2: UNIT TESTS
  # ==========================================================================
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: code-quality
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install tensorflow tensorflow-hub
          pip install pytest pytest-cov
          pip install -r requirements.txt || true
      
      - name: Run unit tests
        run: |
          pytest tests/unit/ -v --tb=short || echo "No unit tests found yet"
      
      - name: Test summary
        if: always()
        run: |
          echo "## Unit Test Results" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Unit tests completed" >> $GITHUB_STEP_SUMMARY

  # ==========================================================================
  # JOB 3: MODEL TRAINING (DEV/STAGING)
  # ==========================================================================
  model-training:
    name: Train Model
    runs-on: ubuntu-latest
    needs: unit-tests
    if: github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install tensorflow tensorflow-hub
          pip install google-cloud-bigquery google-cloud-storage
          pip install pandas numpy scikit-learn datasets
          pip install -r requirements.txt || true
      
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
      
      - name: Train model on sample data
        run: |
          python src/training/train.py \
            --project-id ${{ secrets.GCP_PROJECT_ID }} \
            --sample-size ${{ github.event.inputs.sample_size || '1000' }} \
            --epochs 2 \
            --model-type use \
            --output-path ./models/trained
      
      - name: Upload model artifacts
        uses: actions/upload-artifact@v4
        with:
          name: trained-model
          path: |
            models/trained/*.keras
            models/trained/*.pkl
            models/trained/metadata.json
          retention-days: 30
      
      - name: Training summary
        if: always()
        run: |
          echo "## Model Training Results" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Model training completed" >> $GITHUB_STEP_SUMMARY
          if [ -f models/trained/metadata.json ]; then
            echo "### Metadata:" >> $GITHUB_STEP_SUMMARY
            cat models/trained/metadata.json >> $GITHUB_STEP_SUMMARY
          fi

  # ==========================================================================
  # JOB 4: UPLOAD MODEL TO GCS AND REGISTER TO VERTEX AI
  # ==========================================================================
  upload-model:
    name: Upload Model to GCS and Register
    runs-on: ubuntu-latest
    needs: model-training
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download model artifacts
        uses: actions/download-artifact@v4
        with:
          name: trained-model
          path: ./models/trained
      
      - name: Set up Python for model conversion
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install TensorFlow for model conversion
        run: |
          pip install --upgrade pip
          pip install tensorflow tensorflow-hub
      
      - name: Convert Keras model to SavedModel format
        run: |
          python - <<EOF
          import tensorflow as tf
          import os
          
          # Load the Keras model
          model = tf.keras.models.load_model('models/trained/model.keras')
          
          # Save in SavedModel format
          savedmodel_path = 'models/saved_model'
          os.makedirs(savedmodel_path, exist_ok=True)
          model.export(savedmodel_path)
          
          print(f"âœ… Model converted to SavedModel format at {savedmodel_path}")
          
          # Show directory structure
          import subprocess
          result = subprocess.run(['find', savedmodel_path, '-type', 'f'], capture_output=True, text=True)
          print("Files created:")
          print(result.stdout)
          EOF
      
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}
      
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
      
      - name: Upload to GCS and Register Model
        run: |
          # Calculate timestamp and GCS URI
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          GCS_MODEL_URI="gs://${{ secrets.GCS_BUCKET }}/models/production/${TIMESTAMP}"
          
          echo "Calculated GCS URI: $GCS_MODEL_URI"
          
          # Debug: Show what we're about to upload
          echo "Local SavedModel structure:"
          find models/saved_model -type f
          
          # Upload the entire SavedModel directory with proper structure
          # The -r flag preserves directory structure
          gsutil -m cp -r models/saved_model "${GCS_MODEL_URI}/"
          echo "âœ… SavedModel uploaded to: ${GCS_MODEL_URI}/saved_model"
          
          # Verify what was uploaded
          echo "Verifying GCS contents:"
          gsutil ls -r "${GCS_MODEL_URI}/"
          
          # Also upload other artifacts (label encoder, metadata) to a separate location
          gsutil cp models/trained/label_encoder.pkl "${GCS_MODEL_URI}/artifacts/"
          gsutil cp models/trained/metadata.json "${GCS_MODEL_URI}/artifacts/"
          echo "âœ… Additional artifacts uploaded"
          
          # Register model to Vertex AI Model Registry
          # Point to the saved_model subdirectory where saved_model.pb lives
          MODEL_NAME="consumer-complaints-classifier"
          SERVING_IMAGE="us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest"
          MODEL_ARTIFACT_URI="${GCS_MODEL_URI}/saved_model"
          
          echo "Registering model from URI: ${MODEL_ARTIFACT_URI}"
          
          gcloud ai models upload \
            --project=${{ secrets.GCP_PROJECT_ID }} \
            --region=${{ env.REGION }} \
            --display-name="${MODEL_NAME}" \
            --artifact-uri="${MODEL_ARTIFACT_URI}" \
            --container-image-uri="${SERVING_IMAGE}"
          
          echo "âœ… Model successfully registered to Vertex AI Model Registry"
      
      - name: Upload summary
        run: |
          echo "## Model Upload and Registration" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Model uploaded to GCS and registered to Vertex AI" >> $GITHUB_STEP_SUMMARY

  # ==========================================================================
  # JOB 5: DEPLOYMENT NOTIFICATION
  # ==========================================================================
  notify:
    name: Send Notification
    runs-on: ubuntu-latest
    needs: [code-quality, unit-tests, model-training]
    if: always()
    
    steps:
      - name: Check job statuses
        run: |
          echo "Pipeline Status:"
          echo "  Code Quality: ${{ needs.code-quality.result }}"
          echo "  Unit Tests: ${{ needs.unit-tests.result }}"
          echo "  Model Training: ${{ needs.model-training.result }}"
      
      - name: Create summary
        run: |
          echo "# ðŸš€ MLOps Pipeline Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Results:" >> $GITHUB_STEP_SUMMARY
          echo "- Code Quality: ${{ needs.code-quality.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Unit Tests: ${{ needs.unit-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Model Training: ${{ needs.model-training.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "**Author:** ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY