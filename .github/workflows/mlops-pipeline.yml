# ============================================================================
# GitHub Actions CI/CD Pipeline for MLOps Consumer Complaints Classifier
# TensorFlow Serving + Docker Deployment
# ============================================================================

name: MLOps CI/CD Pipeline

on:
  push:
    branches:
      - main
      - develop
    paths:
      - 'src/**'
      - 'tests/**'
      - 'requirements.txt'
      - 'Dockerfile'
      - '.github/workflows/**'
  
  pull_request:
    branches:
      - main
      - develop
  
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - production
      sample_size:
        description: 'Training sample size'
        required: false
        default: '5000'

permissions:
  id-token: write
  contents: read
  packages: write
  
env:
  PYTHON_VERSION: '3.11'
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  REGION: 'us-central1'
  DOCKER_REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}/tfserving-consumer-complaints

jobs:
  # ==========================================================================
  # JOB 1: CODE QUALITY CHECKS
  # ==========================================================================
  code-quality:
    name: Code Quality & Linting
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install linting tools
        run: |
          pip install black flake8 isort
      
      - name: Run Black (formatting check)
        run: |
          black --check --diff src/ tests/ || true
      
      - name: Run isort (import sorting)
        run: |
          isort --check-only --diff src/ tests/ || true
      
      - name: Run Flake8 (linting)
        run: |
          flake8 src/ tests/ --max-line-length=100 --exclude=__init__.py || true
      
      - name: Code quality summary
        if: always()
        run: |
          echo "## Code Quality Report" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Code quality checks completed" >> $GITHUB_STEP_SUMMARY

  # ==========================================================================
  # JOB 2: UNIT TESTS
  # ==========================================================================
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: code-quality
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install tensorflow tensorflow-hub
          pip install pytest pytest-cov
          pip install -r requirements.txt || true
      
      - name: Run unit tests
        run: |
          pytest tests/unit/ -v --tb=short || echo "No unit tests found yet"
      
      - name: Test summary
        if: always()
        run: |
          echo "## Unit Test Results" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Unit tests completed" >> $GITHUB_STEP_SUMMARY

  # ==========================================================================
  # JOB 3: MODEL TRAINING
  # ==========================================================================
  model-training:
    name: Train Model
    runs-on: ubuntu-latest
    needs: unit-tests
    if: github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install tensorflow tensorflow-hub
          pip install google-cloud-bigquery google-cloud-storage
          pip install pandas numpy scikit-learn datasets
          pip install -r requirements.txt || true
      
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
      
      - name: Train model on sample data
        run: |
          python src/training/train.py \
            --project-id ${{ secrets.GCP_PROJECT_ID }} \
            --sample-size ${{ github.event.inputs.sample_size || '1000' }} \
            --epochs 2 \
            --model-type use \
            --output-path ./models/trained
      
      - name: Upload model artifacts
        uses: actions/upload-artifact@v4
        with:
          name: trained-model
          path: |
            models/trained/*.keras
            models/trained/*.pkl
            models/trained/metadata.json
          retention-days: 30
      
      - name: Training summary
        if: always()
        run: |
          echo "## Model Training Results" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Model training completed" >> $GITHUB_STEP_SUMMARY
          if [ -f models/trained/metadata.json ]; then
            echo "### Metadata:" >> $GITHUB_STEP_SUMMARY
            cat models/trained/metadata.json >> $GITHUB_STEP_SUMMARY
          fi

  # ==========================================================================
  # JOB 4: CONVERT MODEL TO SAVEDMODEL FORMAT
  # ==========================================================================
  convert-model:
    name: Convert to SavedModel
    runs-on: ubuntu-latest
    needs: model-training
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download model artifacts
        uses: actions/download-artifact@v4
        with:
          name: trained-model
          path: ./models/trained
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies for model conversion
        run: |
          pip install --upgrade pip
          pip install tensorflow tensorflow-hub
          pip install -r requirements.txt || true
      
      - name: Convert Keras model to SavedModel format
        run: |
          cat > convert_model.py << 'EOF'
          import sys
          import os
          
          # Add the project root to Python path to import custom layers
          sys.path.insert(0, os.path.abspath('.'))
          
          import tensorflow as tf
          
          print("=" * 60)
          print("Converting model to TensorFlow SavedModel format")
          print("=" * 60)
          
          # Import custom layers/classes before loading the model
          print("\n1. Importing custom layers...")
          try:
              from src.models.use_classifier import USEEmbeddingLayer
              print("   âœ“ USEEmbeddingLayer imported successfully")
              custom_objects = {'USEEmbeddingLayer': USEEmbeddingLayer}
          except ImportError as e:
              print(f"   âš  Could not import USEEmbeddingLayer: {e}")
              custom_objects = None
          
          # Load the Keras model
          print("\n2. Loading Keras model from: models/trained/model.keras")
          if custom_objects:
              model = tf.keras.models.load_model(
                  'models/trained/model.keras',
                  custom_objects=custom_objects
              )
          else:
              model = tf.keras.models.load_model('models/trained/model.keras')
          
          print("   âœ“ Model loaded successfully")
          print(f"   Model type: {type(model).__name__}")
          
          # Create version directory for TensorFlow Serving
          # TF Serving expects models in: /models/<model_name>/<version>/
          version = "1"
          export_path = f'models/tfserving/{version}'
          
          print(f"\n3. Exporting model to: {export_path}")
          
          # Use model.export() for Keras 3 - this creates SavedModel format
          os.makedirs(export_path, exist_ok=True)
          model.export(export_path)
          
          print("   âœ“ Model exported in SavedModel format")
          
          # Verify saved_model.pb exists
          print("\n4. Verifying SavedModel structure:")
          saved_model_pb = os.path.join(export_path, 'saved_model.pb')
          if os.path.exists(saved_model_pb):
              size = os.path.getsize(saved_model_pb)
              print(f"   âœ“ saved_model.pb found ({size:,} bytes)")
          else:
              print("   âœ— ERROR: saved_model.pb NOT found!")
              sys.exit(1)
          
          # Show directory structure
          print("\n5. Directory structure for TensorFlow Serving:")
          import subprocess
          result = subprocess.run(
              ['find', 'models/tfserving', '-type', 'f'], 
              capture_output=True, 
              text=True
          )
          for line in result.stdout.strip().split('\n'):
              if line:
                  print(f"   {line}")
          
          print("\n" + "=" * 60)
          print("âœ… Model conversion completed successfully")
          print("=" * 60)
          EOF
          
          python convert_model.py
      
      - name: Upload SavedModel artifacts
        uses: actions/upload-artifact@v4
        with:
          name: savedmodel
          path: models/tfserving/
          retention-days: 30
      
      - name: Upload label encoder
        uses: actions/upload-artifact@v4
        with:
          name: label-encoder
          path: models/trained/label_encoder.pkl
          retention-days: 30

  # ==========================================================================
  # JOB 5: BUILD AND PUSH DOCKER IMAGE
  # ==========================================================================
  build-docker:
    name: Build TensorFlow Serving Docker Image
    runs-on: ubuntu-latest
    needs: convert-model
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download SavedModel
        uses: actions/download-artifact@v4
        with:
          name: savedmodel
          path: models/tfserving/
      
      - name: Download label encoder
        uses: actions/download-artifact@v4
        with:
          name: label-encoder
          path: models/artifacts/
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.DOCKER_REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Extract metadata for Docker
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
      
      - name: Create Dockerfile for TensorFlow Serving
        run: |
          cat > Dockerfile.serving <<'EOF'
          # Use official TensorFlow Serving image as base
          FROM tensorflow/serving:latest
          
          # Copy the SavedModel to the serving directory
          # TF Serving expects models at /models/<model_name>/<version>/
          COPY models/tfserving /models/consumer-complaints-classifier
          
          # Copy additional artifacts (label encoder, metadata)
          COPY models/artifacts /models/artifacts
          
          # Set environment variables
          ENV MODEL_NAME=consumer-complaints-classifier
          ENV MODEL_BASE_PATH=/models/consumer-complaints-classifier
          
          # Expose TensorFlow Serving ports
          # 8500 - gRPC
          # 8501 - REST API
          EXPOSE 8500 8501
          
          # Health check
          HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
            CMD curl -f http://localhost:8501/v1/models/${MODEL_NAME} || exit 1
          
          # Start TensorFlow Serving
          CMD ["tensorflow_model_server", \
               "--rest_api_port=8501", \
               "--model_name=consumer-complaints-classifier", \
               "--model_base_path=/models/consumer-complaints-classifier"]
          EOF
          
          echo "âœ… Dockerfile.serving created"
          cat Dockerfile.serving
      
      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: Dockerfile.serving
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Docker build summary
        run: |
          echo "## Docker Image Built and Pushed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Image Tags:" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "${{ steps.meta.outputs.tags }}" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Pull Command:" >> $GITHUB_STEP_SUMMARY
          echo '```bash' >> $GITHUB_STEP_SUMMARY
          echo "docker pull ${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}:latest" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

  # ==========================================================================
  # JOB 6: DEPLOY TO GCP (CLOUD RUN)
  # ==========================================================================
  deploy-to-gcp:
    name: Deploy to Google Cloud Run
    runs-on: ubuntu-latest
    needs: build-docker
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}
      
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
      
      - name: Configure Docker for GCP
        run: |
          gcloud auth configure-docker ${{ env.DOCKER_REGISTRY }}
      
      - name: Extract image tag
        id: image
        run: |
          IMAGE_TAG="${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}:latest"
          echo "tag=${IMAGE_TAG}" >> $GITHUB_OUTPUT
          echo "Image to deploy: ${IMAGE_TAG}"
      
      - name: Deploy to Cloud Run
        run: |
          gcloud run deploy consumer-complaints-serving \
            --image=${{ steps.image.outputs.tag }} \
            --platform=managed \
            --region=${{ env.REGION }} \
            --allow-unauthenticated \
            --port=8501 \
            --memory=2Gi \
            --cpu=2 \
            --min-instances=0 \
            --max-instances=10 \
            --timeout=300 \
            --set-env-vars="MODEL_NAME=consumer-complaints-classifier" \
            --project=${{ secrets.GCP_PROJECT_ID }}
      
      - name: Get service URL
        id: service
        run: |
          SERVICE_URL=$(gcloud run services describe consumer-complaints-serving \
            --region=${{ env.REGION }} \
            --format='value(status.url)' \
            --project=${{ secrets.GCP_PROJECT_ID }})
          echo "url=${SERVICE_URL}" >> $GITHUB_OUTPUT
          echo "Service URL: ${SERVICE_URL}"
      
      - name: Test deployment
        run: |
          SERVICE_URL="${{ steps.service.outputs.url }}"
          
          # Test health endpoint
          echo "Testing model metadata endpoint..."
          curl -s "${SERVICE_URL}/v1/models/consumer-complaints-classifier" | jq '.' || echo "Health check failed"
          
          # Test prediction endpoint with sample data
          echo ""
          echo "Testing prediction endpoint..."
          curl -s -X POST "${SERVICE_URL}/v1/models/consumer-complaints-classifier:predict" \
            -H "Content-Type: application/json" \
            -d '{
              "instances": ["I need to dispute a charge on my credit card"]
            }' | jq '.' || echo "Prediction test failed"
      
      - name: Deployment summary
        run: |
          echo "## ðŸš€ Deployment Successful" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Service Details:" >> $GITHUB_STEP_SUMMARY
          echo "- **Service Name:** consumer-complaints-serving" >> $GITHUB_STEP_SUMMARY
          echo "- **Region:** ${{ env.REGION }}" >> $GITHUB_STEP_SUMMARY
          echo "- **URL:** ${{ steps.service.outputs.url }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### API Endpoints:" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "# Model Metadata" >> $GITHUB_STEP_SUMMARY
          echo "GET ${{ steps.service.outputs.url }}/v1/models/consumer-complaints-classifier" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "# Prediction" >> $GITHUB_STEP_SUMMARY
          echo "POST ${{ steps.service.outputs.url }}/v1/models/consumer-complaints-classifier:predict" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

  # ==========================================================================
  # JOB 7: UPLOAD MODEL TO GCS (BACKUP)
  # ==========================================================================
  backup-to-gcs:
    name: Backup Model to GCS
    runs-on: ubuntu-latest
    needs: convert-model
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Download SavedModel
        uses: actions/download-artifact@v4
        with:
          name: savedmodel
          path: models/tfserving/
      
      - name: Download label encoder
        uses: actions/download-artifact@v4
        with:
          name: label-encoder
          path: models/artifacts/
      
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}
      
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
      
      - name: Upload to GCS
        run: |
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          GCS_PATH="gs://${{ secrets.GCS_BUCKET }}/models/backups/${TIMESTAMP}"
          
          echo "Backing up model to: ${GCS_PATH}"
          
          # Upload SavedModel
          gsutil -m cp -r models/tfserving/* "${GCS_PATH}/savedmodel/"
          
          # Upload artifacts
          gsutil cp models/artifacts/label_encoder.pkl "${GCS_PATH}/artifacts/"
          
          echo "âœ… Backup complete"
          echo "GCS_PATH=${GCS_PATH}" >> $GITHUB_ENV
      
      - name: Backup summary
        run: |
          echo "## Backup Complete" >> $GITHUB_STEP_SUMMARY
          echo "Model backed up to: ${{ env.GCS_PATH }}" >> $GITHUB_STEP_SUMMARY

  # ==========================================================================
  # JOB 8: NOTIFICATION
  # ==========================================================================
  notify:
    name: Send Notification
    runs-on: ubuntu-latest
    needs: [code-quality, unit-tests, model-training, deploy-to-gcp]
    if: always()
    
    steps:
      - name: Check job statuses
        run: |
          echo "Pipeline Status:"
          echo "  Code Quality: ${{ needs.code-quality.result }}"
          echo "  Unit Tests: ${{ needs.unit-tests.result }}"
          echo "  Model Training: ${{ needs.model-training.result }}"
          echo "  Deployment: ${{ needs.deploy-to-gcp.result }}"
      
      - name: Create summary
        run: |
          echo "# ðŸš€ MLOps Pipeline Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Pipeline Results:" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Code Quality: ${{ needs.code-quality.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Unit Tests: ${{ needs.unit-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Model Training: ${{ needs.model-training.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Deployment: ${{ needs.deploy-to-gcp.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Deployment Stack:" >> $GITHUB_STEP_SUMMARY
          echo "- **Model Format:** TensorFlow SavedModel" >> $GITHUB_STEP_SUMMARY
          echo "- **Serving:** TensorFlow Serving" >> $GITHUB_STEP_SUMMARY
          echo "- **Container:** Docker" >> $GITHUB_STEP_SUMMARY
          echo "- **Platform:** Google Cloud Run" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "**Author:** ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY