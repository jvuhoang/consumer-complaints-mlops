# ============================================================================
# GitHub Actions CI/CD Pipeline for MLOps Consumer Complaints Classifier
# ============================================================================

name: MLOps CI/CD Pipeline

on:
  push:
    branches:
      - main
      - develop
    paths:
      - 'src/**'
      - 'tests/**'
      - 'requirements.txt'
      - '.github/workflows/**'
  
  pull_request:
    branches:
      - main
      - develop
  
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - production
      sample_size:
        description: 'Training sample size'
        required: false
        default: '5000'

permissions:
  id-token: write
  contents: read
  
env:
  PYTHON_VERSION: '3.11'
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  REGION: 'us-central1'

jobs:
  # ==========================================================================
  # JOB 1: CODE QUALITY CHECKS
  # ==========================================================================
  code-quality:
    name: Code Quality & Linting
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install linting tools
        run: |
          pip install black flake8 isort
      
      - name: Run Black (formatting check)
        run: |
          black --check --diff src/ tests/ || true
      
      - name: Run isort (import sorting)
        run: |
          isort --check-only --diff src/ tests/ || true
      
      - name: Run Flake8 (linting)
        run: |
          flake8 src/ tests/ --max-line-length=100 --exclude=__init__.py || true
      
      - name: Code quality summary
        if: always()
        run: |
          echo "## Code Quality Report" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Code quality checks completed" >> $GITHUB_STEP_SUMMARY

  # ==========================================================================
  # JOB 2: UNIT TESTS
  # ==========================================================================
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: code-quality
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install tensorflow tensorflow-hub
          pip install pytest pytest-cov
          pip install -r requirements.txt || true
      
      - name: Run unit tests
        run: |
          pytest tests/unit/ -v --tb=short || echo "No unit tests found yet"
      
      - name: Test summary
        if: always()
        run: |
          echo "## Unit Test Results" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Unit tests completed" >> $GITHUB_STEP_SUMMARY

  # ==========================================================================
  # JOB 3: MODEL TRAINING (DEV/STAGING)
  # ==========================================================================
  model-training:
    name: Train Model
    runs-on: ubuntu-latest
    needs: unit-tests
    if: github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install tensorflow tensorflow-hub
          pip install google-cloud-bigquery google-cloud-storage
          pip install pandas numpy scikit-learn datasets
          pip install -r requirements.txt || true
      
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
      
      - name: Train model on sample data
        run: |
          python src/training/train.py \
            --project-id ${{ secrets.GCP_PROJECT_ID }} \
            --sample-size ${{ github.event.inputs.sample_size || '1000' }} \
            --epochs 2 \
            --model-type use \
            --output-path ./models/trained
      
      - name: Upload model artifacts
        uses: actions/upload-artifact@v4
        with:
          name: trained-model
          path: |
            models/trained/*.keras
            models/trained/*.pkl
            models/trained/metadata.json
          retention-days: 30
      
      - name: Training summary
        if: always()
        run: |
          echo "## Model Training Results" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Model training completed" >> $GITHUB_STEP_SUMMARY
          if [ -f models/trained/metadata.json ]; then
            echo "### Metadata:" >> $GITHUB_STEP_SUMMARY
            cat models/trained/metadata.json >> $GITHUB_STEP_SUMMARY
          fi

  # ==========================================================================
  # JOB 4: CONVERT, UPLOAD MODEL TO GCS AND REGISTER TO VERTEX AI
  # ==========================================================================
  upload-model:
    name: Upload Model to GCS and Register
    runs-on: ubuntu-latest
    needs: model-training
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download model artifacts
        uses: actions/download-artifact@v4
        with:
          name: trained-model
          path: ./models/trained
      
      - name: Set up Python for model conversion
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install TensorFlow for model conversion
        run: |
          pip install --upgrade pip
          pip install tensorflow tensorflow-hub
      
      - name: Convert Keras model to SavedModel format
        run: |
          python - <<'PYTHON_SCRIPT'
          import tensorflow as tf
          import os
          
          print("=" * 60)
          print("Starting model conversion to SavedModel format")
          print("=" * 60)
          
          # Load the Keras model
          print("\n1. Loading Keras model from: models/trained/model.keras")
          model = tf.keras.models.load_model('models/trained/model.keras')
          print("   âœ“ Model loaded successfully")
          
          # Save in TensorFlow SavedModel format
          export_path = 'models/model_export'
          print(f"\n2. Saving model to: {export_path}")
          model.save(export_path, save_format='tf')
          print("   âœ“ Model saved in SavedModel format")
          
          # Verify saved_model.pb exists
          print("\n3. Verifying SavedModel structure:")
          saved_model_pb = os.path.join(export_path, 'saved_model.pb')
          if os.path.exists(saved_model_pb):
              size = os.path.getsize(saved_model_pb)
              print(f"   âœ“ saved_model.pb found ({size:,} bytes)")
          else:
              print("   âœ— ERROR: saved_model.pb NOT found!")
              exit(1)
          
          # Show complete directory structure
          print("\n4. Complete directory structure:")
          import subprocess
          result = subprocess.run(
              ['find', export_path, '-type', 'f'], 
              capture_output=True, 
              text=True
          )
          for line in result.stdout.strip().split('\n'):
              print(f"   {line}")
          
          print("\n" + "=" * 60)
          print("âœ… Model conversion completed successfully")
          print("=" * 60)
          PYTHON_SCRIPT
      
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}
      
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
      
      - name: Upload SavedModel to GCS and Register to Vertex AI
        run: |
          set -e  # Exit on any error
          
          echo "============================================================"
          echo "Starting GCS Upload and Vertex AI Registration"
          echo "============================================================"
          
          # Calculate timestamp and GCS URI
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          GCS_BASE_PATH="gs://${{ secrets.GCS_BUCKET }}/models/production/${TIMESTAMP}"
          
          echo ""
          echo "Configuration:"
          echo "  Timestamp: ${TIMESTAMP}"
          echo "  GCS Base Path: ${GCS_BASE_PATH}"
          echo "  Project: ${{ secrets.GCP_PROJECT_ID }}"
          echo "  Region: ${{ env.REGION }}"
          echo ""
          
          # Verify local model export exists
          echo "1. Verifying local model export..."
          if [ ! -d "models/model_export" ]; then
            echo "   âœ— ERROR: models/model_export directory not found!"
            exit 1
          fi
          
          if [ ! -f "models/model_export/saved_model.pb" ]; then
            echo "   âœ— ERROR: saved_model.pb not found in models/model_export!"
            exit 1
          fi
          echo "   âœ“ Local model export verified"
          
          echo ""
          echo "   Local files to upload:"
          find models/model_export -type f | sed 's/^/     /'
          
          # Upload the entire model_export directory to GCS
          echo ""
          echo "2. Uploading SavedModel to GCS..."
          gsutil -m cp -r models/model_export "${GCS_BASE_PATH}/"
          echo "   âœ“ Upload complete"
          
          # Verify saved_model.pb exists in GCS
          echo ""
          echo "3. Verifying GCS upload..."
          if gsutil ls "${GCS_BASE_PATH}/model_export/saved_model.pb" &> /dev/null; then
            echo "   âœ“ saved_model.pb confirmed in GCS"
          else
            echo "   âœ— ERROR: saved_model.pb NOT found in GCS at ${GCS_BASE_PATH}/model_export/"
            echo ""
            echo "   GCS directory contents:"
            gsutil ls -r "${GCS_BASE_PATH}/" || true
            exit 1
          fi
          
          echo ""
          echo "   GCS directory structure:"
          gsutil ls -r "${GCS_BASE_PATH}/model_export/" | head -20 | sed 's/^/     /'
          
          # Upload additional artifacts
          echo ""
          echo "4. Uploading additional artifacts..."
          gsutil cp models/trained/label_encoder.pkl "${GCS_BASE_PATH}/artifacts/label_encoder.pkl"
          gsutil cp models/trained/metadata.json "${GCS_BASE_PATH}/artifacts/metadata.json"
          echo "   âœ“ Artifacts uploaded"
          
          # Register model to Vertex AI Model Registry
          MODEL_NAME="consumer-complaints-classifier"
          SERVING_IMAGE="us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest"
          MODEL_ARTIFACT_URI="${GCS_BASE_PATH}/model_export"
          
          echo ""
          echo "5. Registering model to Vertex AI Model Registry..."
          echo "   Model Name: ${MODEL_NAME}"
          echo "   Artifact URI: ${MODEL_ARTIFACT_URI}"
          echo "   Serving Image: ${SERVING_IMAGE}"
          echo ""
          
          gcloud ai models upload \
            --project=${{ secrets.GCP_PROJECT_ID }} \
            --region=${{ env.REGION }} \
            --display-name="${MODEL_NAME}" \
            --artifact-uri="${MODEL_ARTIFACT_URI}" \
            --container-image-uri="${SERVING_IMAGE}"
          
          echo ""
          echo "============================================================"
          echo "âœ… Model successfully registered to Vertex AI Model Registry"
          echo "============================================================"
          echo ""
          echo "Model Details:"
          echo "  GCS Location: ${MODEL_ARTIFACT_URI}"
          echo "  Artifacts: ${GCS_BASE_PATH}/artifacts/"
          echo ""
      
      - name: Upload summary
        if: always()
        run: |
          echo "## Model Upload and Registration" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ $? -eq 0 ]; then
            echo "âœ… Model uploaded to GCS and registered to Vertex AI" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Model upload or registration failed" >> $GITHUB_STEP_SUMMARY
          fi

  # ==========================================================================
  # JOB 5: DEPLOYMENT NOTIFICATION
  # ==========================================================================
  notify:
    name: Send Notification
    runs-on: ubuntu-latest
    needs: [code-quality, unit-tests, model-training]
    if: always()
    
    steps:
      - name: Check job statuses
        run: |
          echo "Pipeline Status:"
          echo "  Code Quality: ${{ needs.code-quality.result }}"
          echo "  Unit Tests: ${{ needs.unit-tests.result }}"
          echo "  Model Training: ${{ needs.model-training.result }}"
      
      - name: Create summary
        run: |
          echo "# ðŸš€ MLOps Pipeline Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Results:" >> $GITHUB_STEP_SUMMARY
          echo "- Code Quality: ${{ needs.code-quality.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Unit Tests: ${{ needs.unit-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Model Training: ${{ needs.model-training.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "**Author:** ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY